# generated by rye
# use `rye lock` or `rye sync` to update this lockfile
#
# last locked with the following flags:
#   pre: false
#   features: []
#   all-features: false
#   with-sources: false
#   generate-hashes: false
#   universal: false

-e file:.
absl-py==2.1.0
asttokens==2.4.1
    # via stack-data
beautifulsoup4==4.12.3
    # via google
comm==0.2.2
    # via ipykernel
contourpy==1.2.1
    # via matplotlib
coverage==7.6.1
    # via pytest-cov
cycler==0.12.1
    # via matplotlib
debugpy==1.8.5
    # via ipykernel
decorator==5.1.1
    # via ipython
einops==0.8.0
exceptiongroup==1.2.2
    # via ipython
    # via pytest
executing==2.0.1
    # via stack-data
ffmpeg==1.4
ffmpeg-python==0.2.0
filelock==3.15.4
    # via torch
    # via triton
flow-vis==0.1
fonttools==4.53.1
    # via matplotlib
fsspec==2024.6.1
    # via torch
future==1.0.0
    # via ffmpeg-python
google==3.0.0
iniconfig==2.0.0
    # via pytest
ipykernel==6.29.5
ipython==8.26.0
    # via ipykernel
    # via mediapy
jedi==0.19.1
    # via ipython
jinja2==3.1.4
    # via torch
joblib==1.4.2
    # via scikit-learn
jupyter-client==8.6.2
    # via ipykernel
jupyter-core==5.7.2
    # via ipykernel
    # via jupyter-client
kiwisolver==1.4.5
    # via matplotlib
kornia==0.7.3
kornia-rs==0.1.5
    # via kornia
mako==1.3.5
markupsafe==2.1.5
    # via jinja2
    # via mako
matplotlib==3.9.2
    # via mediapy
    # via torchshow
matplotlib-inline==0.1.7
    # via ipykernel
    # via ipython
mediapy==1.2.2
mpmath==1.3.0
    # via sympy
mypy==1.11.1
mypy-extensions==1.0.0
    # via mypy
nest-asyncio==1.6.0
    # via ipykernel
networkx==3.3
    # via torch
numpy==2.0.1
    # via contourpy
    # via flow-vis
    # via matplotlib
    # via mediapy
    # via opencv-python
    # via scikit-learn
    # via scipy
    # via tensorboardx
    # via torchshow
    # via torchvision
nvidia-cublas-cu12==12.1.3.1
    # via nvidia-cudnn-cu12
    # via nvidia-cusolver-cu12
    # via torch
nvidia-cuda-cupti-cu12==12.1.105
    # via torch
nvidia-cuda-nvrtc-cu12==12.1.105
    # via torch
nvidia-cuda-runtime-cu12==12.1.105
    # via torch
nvidia-cudnn-cu12==9.1.0.70
    # via torch
nvidia-cufft-cu12==11.0.2.54
    # via torch
nvidia-curand-cu12==10.3.2.106
    # via torch
nvidia-cusolver-cu12==11.4.5.107
    # via torch
nvidia-cusparse-cu12==12.1.0.106
    # via nvidia-cusolver-cu12
    # via torch
nvidia-nccl-cu12==2.20.5
    # via torch
nvidia-nvjitlink-cu12==12.6.20
    # via nvidia-cusolver-cu12
    # via nvidia-cusparse-cu12
nvidia-nvtx-cu12==12.1.105
    # via torch
opencv-python==4.10.0.84
packaging==24.1
    # via ipykernel
    # via kornia
    # via matplotlib
    # via pytest
    # via tensorboardx
parso==0.8.4
    # via jedi
pexpect==4.9.0
    # via ipython
pillow==10.4.0
    # via matplotlib
    # via mediapy
    # via torchvision
platformdirs==4.2.2
    # via jupyter-core
pluggy==1.5.0
    # via pytest
prompt-toolkit==3.0.47
    # via ipython
protobuf==5.27.3
    # via tensorboardx
psutil==6.0.0
    # via ipykernel
ptyprocess==0.7.0
    # via pexpect
pure-eval==0.2.3
    # via stack-data
pygments==2.18.0
    # via ipython
pyparsing==3.1.2
    # via matplotlib
pytest==8.3.2
    # via pytest-cov
pytest-cov==5.0.0
python-dateutil==2.9.0.post0
    # via jupyter-client
    # via matplotlib
pyzmq==26.1.0
    # via ipykernel
    # via jupyter-client
ruff==0.6.1
scikit-learn==1.5.1
scipy==1.14.0
    # via scikit-learn
six==1.16.0
    # via asttokens
    # via python-dateutil
soupsieve==2.6
    # via beautifulsoup4
stack-data==0.6.3
    # via ipython
sympy==1.13.2
    # via torch
tensorboardx==2.6.2.2
threadpoolctl==3.5.0
    # via scikit-learn
tomli==2.0.1
    # via coverage
    # via mypy
    # via pytest
torch==2.4.0
    # via kornia
    # via sakuramoti
    # via torchvision
torchshow==0.5.1
torchvision==0.19.0
tornado==6.4.1
    # via ipykernel
    # via jupyter-client
tqdm==4.66.5
traitlets==5.14.3
    # via comm
    # via ipykernel
    # via ipython
    # via jupyter-client
    # via jupyter-core
    # via matplotlib-inline
triton==3.0.0
    # via torch
typing-extensions==4.12.2
    # via ipython
    # via mypy
    # via torch
wcwidth==0.2.13
    # via prompt-toolkit
